# 数据集分割
* 验证数据集：一个用来评估模型好坏的数据集
    * 例如拿出50%的训练数据
    * 不要跟训练数据混在一起（常犯错误）
* 测试数据集：只用一次的数据集。例如
    * 未来的考试
    * 我出价的房子的实际成交价
    * 用在Kaggle私有排行榜的数据集
* K-折交叉验证
    * 在没有足够多数据时使用（这是常态）
    * 算法：
        * 将训练数据分割成K块
        * for i = 1, .., K
            * 使用第i块作为验证数据集，其余的作为训练数据集
        * 报告K跟验证集误差的平均
    * 常用： K = 5 或 10
# 过拟合和欠拟合

| 模型容量 | 简单    | 复杂  |
|:--------:|:-------:|:-----:|
|低        | 正常    |欠拟合 |
|高        | 欠拟合  |正常   |

## 模型容量
* 拟合各种函数的能力
* 低容量的模型难以拟合训练数据
* 高容量的模型可以记住所有的训练数据

## 估计模型容量
* 难以在不同种类算法之间比较
    * 例如树模型和神经网络
* 给定一个模型种类， 将有两个主要因素
    * 参数的个数
    * 参数值的选择范围

## VC维
* 统计学习理论的一个核心思想
* 对于一个分类模型，VC等于一个最大的数据集大小，不管如果给定label，都存在一个模型对它进行完美分类
    * 2维输入的感知机，VC维=3
    * 能够分类任何3高点，但不是4个（xor）
* 支持N维输入的感知机的VC维是N+1
* 一些多层感知机的VC维$O(Nlog_2N)$
* VC维的好处
    * 提供为什么一个模型好的理论依据
        * 它可以衡量训练误差和泛化误差之间的间隔
    * 但深度学习中很少使用
        * 衡量不是很准确
        * 计算深度学习模型的VC维很困难

# 数据复杂度
* 多个重要因素
    * 样本个数
    * 美国样本的元素个数
    * 时间、空间结构
    * 多样性

### 实际中一般靠观察实际误差(train set)和训练误差(valid set)来判断过拟合or欠拟合

# QA
* 如果是2分类问题，实际情况是1/9的比例，我的训练集两种类型比例应该是1/1还是1/9？
    * ans：建议是1/1，或者调整样本权重
* k折交叉验证的目的是确定超参数吗？确定后这个超参数要重训一遍全量数据吗？
    * ans：三种做法，1，就是全量重训一次。2. 只使用效果最好的K-Fold（不建议）。3.K个模型全部用来预测取均值。
* 
